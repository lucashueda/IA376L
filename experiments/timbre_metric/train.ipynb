{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timbre metric training\n",
    "\n",
    "This notebook was used to train the timbre distance metric. We use the triplet network implementation from the [ISMIR 2020 metric learning tutorial](https://github.com/bmcfee/ismir2020-metric-learning/).\n",
    "\n",
    "Copyright 2020 InterDigital R&D and Télécom Paris.  \n",
    "Author: Ondřej Cífka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "import tempfile\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine as cosine_distance\n",
    "import tensorflow as tf\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from ss_vq_vae.models import triplet_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 16000\n",
    "BATCH_SIZE = 16\n",
    "DATA_DIR = '../data/mixing_secrets/metric_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_mfcc(path):\n",
    "    a, _ = librosa.load(path, sr=SR)\n",
    "    return librosa.feature.mfcc(a, sr=SR, n_mfcc=13, hop_length=500)[1:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"backbone\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, None, 12)]        0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, None, 64)          3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, None, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, None, 64)          16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, None, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, None, 64)          16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, None, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, None, 64)          8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, None, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_3 ( (None, 64)                0         \n",
      "=================================================================\n",
      "Total params: 45,312\n",
      "Trainable params: 44,800\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "Model: \"triplet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "anchor_input (InputLayer)       [(None, None, 12)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive_input (InputLayer)     [(None, None, 12)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative_input (InputLayer)     [(None, None, 12)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "backbone (Functional)           (None, 64)           45312       anchor_input[0][0]               \n",
      "                                                                 positive_input[0][0]             \n",
      "                                                                 negative_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1)            0           backbone[0][0]                   \n",
      "                                                                 backbone[1][0]                   \n",
      "                                                                 backbone[0][0]                   \n",
      "                                                                 backbone[2][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 2, 1)         0           lambda_6[0][0]                   \n",
      "                                                                 lambda_6[1][0]                   \n",
      "==================================================================================================\n",
      "Total params: 45,312\n",
      "Trainable params: 44,800\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model, backbone = triplet_network.build_model(num_features=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/tmpzxvrbtdy'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TMP_DIR = tempfile.mkdtemp()\n",
    "TMP_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee07e57c65548dc88bb7b4c78fbbbfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7381.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cache the pre-processed dataset in the temporary directory\n",
    "single_loader, dataset_size = triplet_network.data_loader(os.path.join(DATA_DIR, 'triplets_train'), load_fn=load_audio_mfcc, batch_size=1)\n",
    "i_len = len(str(dataset_size - 1))\n",
    "with open(os.path.join(TMP_DIR, 'list'), 'w') as f_list:\n",
    "    for i, (triplet, _) in tqdm(enumerate(single_loader()), total=dataset_size):\n",
    "        paths = []\n",
    "        for name in ['anchor', 'positive', 'negative']:\n",
    "            [example] = triplet[name + '_input']\n",
    "            path = '{}_{}.npy'.format(str(i).zfill(i_len), name)\n",
    "            np.save(os.path.join(TMP_DIR, path), example, allow_pickle=False)\n",
    "            paths.append(path)\n",
    "        print(*paths, sep='\\t', file=f_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, steps_per_epoch = triplet_network.data_loader(os.path.join(TMP_DIR, 'list'), load_fn=np.load, batch_size=BATCH_SIZE, shuffle=True, repeat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader, val_dataset_size = triplet_network.data_loader(os.path.join(DATA_DIR, 'triplets_val'), load_fn=load_audio_mfcc, batch_size=1)\n",
    "val_data = list(val_loader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n",
      "[[0.97825205 0.92818373]\n",
      " [0.9945916  0.9573082 ]\n",
      " [0.98921    0.91431683]\n",
      " [0.8972999  0.86211026]]\n",
      "461/461 [==============================] - 15s 32ms/step - loss: 0.0040\n",
      "Accuracy: 0.98\n",
      "[[0.9114496  0.2761086 ]\n",
      " [0.9806918  0.2920639 ]\n",
      " [0.9503249  0.32286048]\n",
      " [0.78040844 0.36132288]]\n",
      "461/461 [==============================] - 15s 33ms/step - loss: 0.0028\n",
      "Accuracy: 0.98\n",
      "[[0.855681   0.319054  ]\n",
      " [0.94909924 0.53117394]\n",
      " [0.9613851  0.36606544]\n",
      " [0.8170693  0.27370113]]\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr=0.001)\n",
    "\n",
    "model.compile(optimizer, loss=triplet_network.triplet_hinge_loss)\n",
    "\n",
    "for _ in range(2):\n",
    "    pred = model.predict(iter(val_data)).reshape(-1, 2)\n",
    "    print('Accuracy:', np.mean(pred.argmax(axis=1) == 0))\n",
    "    print(pred[:4])\n",
    "    \n",
    "    model.fit(train_loader(),\n",
    "        epochs=1,\n",
    "        verbose=1,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "    )\n",
    "\n",
    "\n",
    "pred = model.predict(iter(val_data)).reshape(-1, 2)\n",
    "print('Accuracy:', np.mean(pred.argmax(axis=1) == 0))\n",
    "print(pred[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('checkpoint.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
