{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LMD training data preparation\n",
    "\n",
    "This notebook prepares the synthetic training audio based on the Lakh MIDI Dataset (LMD). Run `../note_seq/prepare.ipynb` first.\n",
    "\n",
    "The code creates a `wav_16kHz` directory containing the 8-second training segments, a `metadata.json` file with information about each segment, and `pairs_train`, `pairs_val` and `pairs_test` files listing pairs of audio file paths. Note that `pairs_test` is not used in the paper, but the corresponding MIDI files are used to generate the artificial test set in `../audio_test/`.\n",
    "\n",
    "Copyright 2020 InterDigital R&D and Télécom Paris.  \n",
    "Author: Ondřej Cífka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\Anaconda3\\envs\\project\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures as cf\n",
    "import glob\n",
    "import hashlib\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import librosa\n",
    "from natsort import natsorted, ns\n",
    "import note_seq\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pretty_midi\n",
    "import pysndfx\n",
    "import soundfile as sf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = '../note_seq/data/'\n",
    "OUTPUT_DIR = 'wav_16kHz'\n",
    "TOTAL_FILES = 169556\n",
    "SR = 16000\n",
    "SF_PATHS = {\n",
    "    'train': [\n",
    "        '../../soundfonts/fluid-soundfont-3.1/FluidR3_GM.sf2',\n",
    "        '../../soundfonts/TimGM6mb.sf2',\n",
    "        '../../soundfonts/Arachno SoundFont - Version 1.0.sf2'\n",
    "    ],\n",
    "    'val': [\n",
    "        '../../soundfonts/fluid-soundfont-3.1/FluidR3_GM.sf2',\n",
    "        '../../soundfonts/TimGM6mb.sf2',\n",
    "        '../../soundfonts/Arachno SoundFont - Version 1.0.sf2'\n",
    "    ],\n",
    "    'test': [\n",
    "        '../../soundfonts/TimbresOfHeaven/Timbres Of Heaven (XGM) 3.94.sf2'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Load data augmentation parameters from metadata_ref.json instead of sampling them randomly.\n",
    "# Set to True to reproduce the dataset from the paper. Set to False if you want to use your own data.\n",
    "USE_REF_METADATA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_REF_METADATA:\n",
    "    with open('metadata_ref.json') as f:\n",
    "        metadata_ref = json.load(f)\n",
    "    metadata_ref_flat = {key: val for section in metadata_ref for key, val in metadata_ref[section].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sequence(sequence, instrument_re=None, instrument_ids=None, programs=None, drums=None,\n",
    "                    copy=False):\n",
    "    if copy:\n",
    "        sequence, original_sequence = music_pb2.NoteSequence(), sequence\n",
    "        sequence.CopyFrom(original_sequence)\n",
    "\n",
    "    if isinstance(instrument_re, str):\n",
    "        instrument_re = re.compile(instrument_re)\n",
    "\n",
    "    # Filter the instruments based on name and ID\n",
    "    deleted_ids = set()\n",
    "    if instrument_re is not None:\n",
    "        deleted_ids.update(i.instrument for i in sequence.instrument_infos\n",
    "                           if not instrument_re.search(i.name))\n",
    "    if instrument_ids is not None:\n",
    "        deleted_ids.update(i.instrument for i in sequence.instrument_infos\n",
    "                           if i.instrument not in instrument_ids)\n",
    "    new_infos = [i for i in sequence.instrument_infos if i.instrument not in deleted_ids]\n",
    "    del sequence.instrument_infos[:]\n",
    "    sequence.instrument_infos.extend(new_infos)\n",
    "\n",
    "    # Filter the event collections\n",
    "    for collection in [sequence.notes, sequence.pitch_bends, sequence.control_changes]:\n",
    "        collection_copy = list(collection)\n",
    "        del collection[:]\n",
    "\n",
    "        for event in collection_copy:\n",
    "            if event.instrument in deleted_ids:\n",
    "                continue\n",
    "            if instrument_ids is not None and event.instrument not in instrument_ids:\n",
    "                continue\n",
    "            if programs is not None and event.program not in programs:\n",
    "                continue\n",
    "            if drums is not None and event.is_drum != drums:\n",
    "                continue\n",
    "            collection.add().CopyFrom(event)\n",
    "\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_fx(rng):\n",
    "    chain = pysndfx.AudioEffectsChain()\n",
    "    for _ in range(rng.choice([0, 1, 2, 3], p=[0.35, 0.4, 0.2, 0.05])):\n",
    "        effect = rng.choice([\n",
    "            lambda c: c.overdrive(gain=rng.uniform(10, 40)),\n",
    "            lambda c: c.phaser(gain_in=rng.uniform(0.6, 0.9),\n",
    "                               gain_out=rng.uniform(0.66, 0.85),\n",
    "                               delay=rng.power(0.4) * 3 + 1,\n",
    "                               decay=rng.uniform(0.2, 0.45),\n",
    "                               speed=rng.uniform(0.5, 2),\n",
    "                               triangular=rng.choice([True, False])),\n",
    "            lambda c: c.gain(-3).reverb(),\n",
    "            lambda c: c.tremolo(freq=rng.power(0.5) * 14 + 1,\n",
    "                                depth=rng.uniform(20, 60))\n",
    "        ])\n",
    "        effect(chain)\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(args):\n",
    "    path, sf_paths = args\n",
    "\n",
    "    if USE_REF_METADATA:\n",
    "        meta_key = os.path.splitext(os.path.basename(path))[0]\n",
    "        meta_ref = metadata_ref_flat.get(meta_key)\n",
    "        if meta_ref is None:\n",
    "            return None\n",
    "    else:\n",
    "        # Use filename as seed\n",
    "        seed = os.path.relpath(path, INPUT_DIR).encode()\n",
    "        seed = int.from_bytes(hashlib.sha512(seed).digest(), 'big')\n",
    "        rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "    with open(path, 'rb') as f:\n",
    "        ns = pickle.load(f)\n",
    "    if not ns.instrument_infos:\n",
    "        return None\n",
    "    max_instrument = max(ii.instrument for ii in ns.instrument_infos)\n",
    "    \n",
    "    meta = {\n",
    "        'src_path': os.path.relpath(path, INPUT_DIR)\n",
    "    }\n",
    "\n",
    "    # Pick a random instrument\n",
    "    if USE_REF_METADATA:\n",
    "        instrument, program = meta_ref['instrument'], meta_ref['src_program']\n",
    "    else:\n",
    "        choices = sorted(set((n.instrument, n.program) for n in ns.notes if not n.is_drum))\n",
    "        if not choices:\n",
    "            return None\n",
    "        instrument, program = choices[rng.choice(len(choices))]\n",
    "    filter_sequence(ns, instrument_ids={instrument})\n",
    "    meta['instrument'], meta['src_program'] = instrument, program\n",
    "\n",
    "    # Change the program randomly\n",
    "    if USE_REF_METADATA:\n",
    "        program = meta_ref['program']\n",
    "    else:\n",
    "        if program < 32:  # Keyboards, guitars\n",
    "            program = rng.choice(32)\n",
    "        elif program >= 40 and program < 80:  # Strings, ensemble, brass, reed, pipe\n",
    "            program = 40 + rng.choice(80 - 40)\n",
    "        elif program < 104:\n",
    "            # Pick a random program from the same class\n",
    "            program = program - (program % 8) + rng.choice(8)\n",
    "    meta['program'] = program\n",
    "\n",
    "    for note in ns.notes:\n",
    "        note.program = program\n",
    "\n",
    "    # Pick a random SoundFont\n",
    "    if USE_REF_METADATA:\n",
    "        [sf_path] = [p for p in sf_paths if os.path.basename(p) == meta_ref['soundfont']]\n",
    "    else:\n",
    "        sf_path = rng.choice(sf_paths)\n",
    "    meta['soundfont'] = os.path.basename(sf_path)\n",
    "\n",
    "    # Pick two non-silent segments\n",
    "    boundaries = np.arange(0., ns.total_time, 8.)\n",
    "    if USE_REF_METADATA:\n",
    "        indices = [s['index'] for s in meta_ref['segments']]\n",
    "    else:\n",
    "        onset_counts, _ = np.histogram([n.start_time for n in ns.notes], bins=boundaries)\n",
    "        activity_map = (onset_counts >= 4)  # arbitrary threshold\n",
    "        [candidates] = np.nonzero(activity_map)\n",
    "        if len(candidates) < 2:\n",
    "            return None\n",
    "        indices = rng.choice(candidates, 2, replace=False)\n",
    "    \n",
    "    # Pick random effects\n",
    "    if USE_REF_METADATA:\n",
    "        effects = pysndfx.AudioEffectsChain()\n",
    "        effects.command = meta_ref['effects']\n",
    "    else:\n",
    "        effects = random_fx(rng)\n",
    "    meta['effects'] = effects.command\n",
    "    \n",
    "    meta['segments'] = []\n",
    "    for ii, i in enumerate(indices):\n",
    "        # Extract the chosen segment\n",
    "        segment = note_seq.sequences_lib.extract_subsequence(ns, boundaries[i], boundaries[i + 1])\n",
    "        \n",
    "        # Transpose by a random amount (up to a fourth)\n",
    "        if USE_REF_METADATA:\n",
    "            assert i == meta_ref['segments'][ii]['index']\n",
    "            transposition = meta_ref['segments'][ii]['transposition']\n",
    "        else:\n",
    "            transposition = rng.choice(np.arange(-5, 6))\n",
    "        note_seq.sequences_lib.transpose_note_sequence(segment, transposition, in_place=True)\n",
    "\n",
    "        # Synthesize it\n",
    "        audio = note_seq.midi_synth.fluidsynth(segment, sf2_path=sf_path, sample_rate=SR)\n",
    "        \n",
    "        # Apply effects\n",
    "        if len(audio) > 0:\n",
    "            audio = effects(audio, sample_in=SR)\n",
    "\n",
    "        # Clip to 8 seconds\n",
    "        audio = audio[:8 * SR]\n",
    "\n",
    "        instrument_len = len(str(max_instrument))\n",
    "        i_len = len(str(len(boundaries) + 1))\n",
    "        out_path = os.path.splitext(path)[0] + f'.{str(instrument).zfill(instrument_len)}.{str(i).zfill(i_len)}.wav'\n",
    "        out_path = os.path.join(OUTPUT_DIR, os.path.relpath(out_path, INPUT_DIR))\n",
    "        os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "        sf.write(out_path, audio, SR, subtype='PCM_24')\n",
    "\n",
    "        meta['segments'].append({\n",
    "            'path': os.path.relpath(out_path, OUTPUT_DIR),\n",
    "            'index': i,\n",
    "            'transposition': transposition\n",
    "        })\n",
    "\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' nÆo ‚ reconhecido como um comando interno\n",
      "ou externo, um programa oper vel ou um arquivo em lotes.\n"
     ]
    }
   ],
   "source": [
    "!rm -r {OUTPUT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No soundfont file found at the supplied path ../../soundfonts/TimbresOfHeaven/Timbres Of Heaven (XGM) 3.94.sf2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m aux_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args:\n\u001b[1;32m---> 24\u001b[0m     aux_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43mprocess_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     26\u001b[0m metadata[dset] \u001b[38;5;241m=\u001b[39m aux_list\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36mprocess_file\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     90\u001b[0m note_seq\u001b[38;5;241m.\u001b[39msequences_lib\u001b[38;5;241m.\u001b[39mtranspose_note_sequence(segment, transposition, in_place\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# Synthesize it\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m audio \u001b[38;5;241m=\u001b[39m \u001b[43mnote_seq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmidi_synth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfluidsynth\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msf2_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# Apply effects\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(audio) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\project\\lib\\site-packages\\note_seq\\midi_synth.py:55\u001b[0m, in \u001b[0;36mfluidsynth\u001b[1;34m(sequence, sample_rate, sf2_path)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m\"\"\"Synthesizes audio from a music_pb2.NoteSequence using FluidSynth.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03mThis uses the pretty_midi `fluidsynth` method. In order to use this synth,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m  A 1-D numpy float array containing the synthesized waveform.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     54\u001b[0m midi \u001b[38;5;241m=\u001b[39m midi_io\u001b[38;5;241m.\u001b[39mnote_sequence_to_pretty_midi(sequence)\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmidi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfluidsynth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msf2_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msf2_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\project\\lib\\site-packages\\pretty_midi\\pretty_midi.py:945\u001b[0m, in \u001b[0;36mPrettyMIDI.fluidsynth\u001b[1;34m(self, fs, sf2_path)\u001b[0m\n\u001b[0;32m    943\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[0;32m    944\u001b[0m \u001b[38;5;66;03m# Get synthesized waveform for each instrument\u001b[39;00m\n\u001b[1;32m--> 945\u001b[0m waveforms \u001b[38;5;241m=\u001b[39m [i\u001b[38;5;241m.\u001b[39mfluidsynth(fs\u001b[38;5;241m=\u001b[39mfs,\n\u001b[0;32m    946\u001b[0m                           sf2_path\u001b[38;5;241m=\u001b[39msf2_path) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstruments]\n\u001b[0;32m    947\u001b[0m \u001b[38;5;66;03m# Allocate output waveform, with #sample = max length of all waveforms\u001b[39;00m\n\u001b[0;32m    948\u001b[0m synthesized \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(np\u001b[38;5;241m.\u001b[39mmax([w\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m waveforms]))\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\project\\lib\\site-packages\\pretty_midi\\pretty_midi.py:945\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    943\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[0;32m    944\u001b[0m \u001b[38;5;66;03m# Get synthesized waveform for each instrument\u001b[39;00m\n\u001b[1;32m--> 945\u001b[0m waveforms \u001b[38;5;241m=\u001b[39m [\u001b[43mi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfluidsynth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m                          \u001b[49m\u001b[43msf2_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msf2_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstruments]\n\u001b[0;32m    947\u001b[0m \u001b[38;5;66;03m# Allocate output waveform, with #sample = max length of all waveforms\u001b[39;00m\n\u001b[0;32m    948\u001b[0m synthesized \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(np\u001b[38;5;241m.\u001b[39mmax([w\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m waveforms]))\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\project\\lib\\site-packages\\pretty_midi\\instrument.py:460\u001b[0m, in \u001b[0;36mInstrument.fluidsynth\u001b[1;34m(self, fs, sf2_path)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfluidsynth() was called but pyfluidsynth \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    457\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(sf2_path):\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo soundfont file found at the supplied path \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    461\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(sf2_path))\n\u001b[0;32m    463\u001b[0m \u001b[38;5;66;03m# If the instrument has no notes, return an empty array\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotes) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: No soundfont file found at the supplied path ../../soundfonts/TimbresOfHeaven/Timbres Of Heaven (XGM) 3.94.sf2"
     ]
    }
   ],
   "source": [
    "# Changed to run on windows, not parallel\n",
    "os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "if USE_REF_METADATA:\n",
    "    train_paths, val_paths, test_paths = (\n",
    "        [os.path.join(INPUT_DIR, x['src_path']) for x in metadata_ref[k].values()]\n",
    "        for k in ['train', 'val', 'test'])\n",
    "    paths = [*train_paths, *val_paths, *test_paths]\n",
    "else:\n",
    "    paths = list(tqdm(glob.iglob(os.path.join(INPUT_DIR, '**', '*.pickle'), recursive=True), desc='collect', total=TOTAL_FILES))\n",
    "    paths.sort()\n",
    "\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(paths)\n",
    "    train_paths, test_paths = train_test_split(paths, test_size=0.01)\n",
    "    train_paths, val_paths = train_test_split(train_paths, test_size=800)\n",
    "\n",
    "metadata = {}\n",
    "\n",
    "for path_list, dset in [(train_paths, 'train'), (val_paths, 'val'), (test_paths, 'test')]:\n",
    "    args = [(p, SF_PATHS[dset]) for p in path_list]\n",
    "    aux_list = []\n",
    "    for arg in args:\n",
    "        aux_list.append(process_file(arg))\n",
    "        \n",
    "    metadata[dset] = aux_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119520 / 169556 files converted successfully\n"
     ]
    }
   ],
   "source": [
    "metadata = {k: [p for p in metadata[k] if p is not None] for k in metadata}\n",
    "\n",
    "print(sum(len(m) for m in metadata.values()), '/', TOTAL_FILES, 'files converted successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "# if USE_REF_METADATA:\n",
    "#     train_paths, val_paths, test_paths = (\n",
    "#         [os.path.join(INPUT_DIR, x['src_path']) for x in metadata_ref[k].values()]\n",
    "#         for k in ['train', 'val', 'test'])\n",
    "#     paths = [*train_paths, *val_paths, *test_paths]\n",
    "# else:\n",
    "#     paths = list(tqdm(glob.iglob(os.path.join(INPUT_DIR, '**', '*.pickle'), recursive=True), desc='collect', total=TOTAL_FILES))\n",
    "#     paths.sort()\n",
    "\n",
    "#     np.random.seed(42)\n",
    "#     np.random.shuffle(paths)\n",
    "#     train_paths, test_paths = train_test_split(paths, test_size=0.01)\n",
    "#     train_paths, val_paths = train_test_split(train_paths, test_size=800)\n",
    "\n",
    "# metadata = {}\n",
    "# with cf.ProcessPoolExecutor(16) as pool:\n",
    "#     for path_list, dset in [(train_paths, 'train'), (val_paths, 'val'), (test_paths, 'test')]:\n",
    "#         args = [(p, SF_PATHS[dset]) for p in path_list]\n",
    "#         metadata[dset] = list(tqdm(\n",
    "#             pool.map(process_file, args, chunksize=100),\n",
    "#             desc=f'convert {dset}', total=len(path_list)))\n",
    "\n",
    "# metadata = {k: [p for p in metadata[k] if p is not None] for k in metadata}\n",
    "\n",
    "# print(sum(len(m) for m in metadata.values()), '/', TOTAL_FILES, 'files converted successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {k: {os.path.splitext(os.path.basename(m['src_path']))[0]: m for m in metadata[k]}\n",
    "            for k in metadata}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumPyJSONEncoder(json.JSONEncoder):\n",
    "    def default(self, x):\n",
    "        if isinstance(x, (np.ndarray, np.generic)):\n",
    "            return x.tolist()\n",
    "        else:\n",
    "            return super().default(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, cls=NumPyJSONEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tuples(tuples, path, shuffle_items=False):\n",
    "    with open(path, 'w') as f:\n",
    "        for tup in tuples:\n",
    "            if shuffle_items:\n",
    "                tup = np.random.choice(tup, size=len(tup), replace=False)\n",
    "            print(*tup, sep='\\t', file=f)\n",
    "\n",
    "np.random.seed(42)\n",
    "# for dset in ['train', 'val', 'test']:\n",
    "for dset in ['train', 'val']:\n",
    "    path_pairs = [(os.path.join(OUTPUT_DIR, a['path']), os.path.join(OUTPUT_DIR, b['path']))\n",
    "                  for m in metadata[dset].values() for a, b in [m['segments']]]\n",
    "    path_pairs.sort()\n",
    "    np.random.shuffle(path_pairs)\n",
    "    write_tuples(path_pairs, f'pairs_{dset}', shuffle_items=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l pairs_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
